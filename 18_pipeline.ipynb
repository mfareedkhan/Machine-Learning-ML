{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pipeline in Machine Learning**\n",
    "\n",
    "In machine learning, a pipeline is a sequence of data processing steps that are chained together to automate and streamline the machine learning workflow. A pipeline allows you to combine multiple data preprocessing and model training steps into a single object, making it easier to organize and manage your machine learning code.\n",
    "\n",
    "> **Here are the key components of a pipeline:**\n",
    "\n",
    "**`Data Preprocessing Steps:`**\n",
    "Pipelines typically start with data preprocessing steps, such as feature scaling, feature encoding, handling missing values, or dimensionality reduction. These steps ensure that the data is in the appropriate format and quality for model training.\n",
    "\n",
    "**`Model Training:`**\n",
    "After the data preprocessing steps, the pipeline includes the training of a machine learning model. This can be a classifier for classification tasks, a regressor for regression tasks, or any other type of model depending on the problem at hand.\n",
    "\n",
    "**`Model Evaluation:`**\n",
    "Once the model is trained, the pipeline often incorporates steps for evaluating its performance. This may involve metrics calculation, cross-validation, or any other evaluation technique to assess the model's effectiveness.\n",
    "\n",
    "**`Predictions:`**\n",
    "After the model has been evaluated, the pipeline allows you to make predictions on new, unseen data using the trained model. This step applies the same preprocessing steps used during training to the new data before generating predictions.\n",
    "\n",
    "\n",
    "> **The main advantages of using pipelines in machine learning are:**\n",
    "\n",
    "**`Simplified Workflow:`** Pipelines provide a clean and organized structure for defining and managing the sequence of steps involved in machine learning tasks. This makes it easier to understand, modify, and reproduce the workflow.\n",
    "\n",
    "**`Avoiding Data Leakage:`** Pipelines ensure that data preprocessing steps are applied consistently to both the training and testing data, preventing data leakage that could lead to biased or incorrect results.\n",
    "\n",
    "**`Streamlined Model Deployment:`** Pipelines allow you to encapsulate the entire workflow, including data preprocessing and model training, into a single object. This simplifies the deployment of your machine learning model, as the same pipeline can be applied to new data without the need to reapply each individual step.\n",
    "\n",
    "**`Hyperparameter Tuning:`** Pipelines can be combined with techniques like grid search or randomized search for hyperparameter tuning. This allows you to efficiently explore different combinations of hyperparameters for your models.\n",
    "\n",
    "----\n",
    "**Summary:**\n",
    "\n",
    "\n",
    "Overall, pipelines are a powerful tool for managing and automating the machine learning workflow, promoting code reusability, consistency, and efficiency. They help streamline the development and deployment of machine learning models, making it easier to iterate and experiment with different approaches."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of using a pipeline on the Titanic dataset to preprocess the data, train a model, and make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7821229050279329\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Titanic dataset from Seaborn\n",
    "titanic_data = sns.load_dataset('titanic')\n",
    "\n",
    "# Select features and target variable\n",
    "X = titanic_data[['pclass', 'sex', 'age', 'fare', 'embarked']]\n",
    "y = titanic_data['survived']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the column transformer for imputing missing values\n",
    "numeric_features = ['age', 'fare']\n",
    "categorical_features = ['pclass', 'sex', 'embarked']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with the preprocessor and RandomForestClassifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is using a machine learning pipeline to preprocess the Titanic dataset and train a `RandomForestClassifier`. Here's a breakdown of the code:\n",
    "\n",
    "- The Titanic dataset is loaded and the features (`X`) and target variable (`y`) are selected.\n",
    "\n",
    "- The data is split into training and test sets using `train_test_split`.\n",
    "\n",
    "- Two pipelines are defined for preprocessing the data: `numeric_transformer` and `categorical_transformer`. \n",
    "  - The `numeric_transformer` pipeline imputes missing values in numeric features with the median value. \n",
    "  - The `categorical_transformer` pipeline imputes missing values in categorical features with the most frequent value and then applies one-hot encoding.\n",
    "\n",
    "- A `ColumnTransformer` named `preprocessor` is defined to apply the appropriate transformer to the appropriate columns.\n",
    "\n",
    "- A final pipeline is created that first applies the `preprocessor` to the data and then trains a `RandomForestClassifier`.\n",
    "\n",
    "- The pipeline is fitted on the training data and used to make predictions on the test data.\n",
    "\n",
    "- The accuracy of the predictions is calculated using `accuracy_score` and printed out.\n",
    "\n",
    "**Observations from the Output:**\n",
    "> The output shows that the accuracy of the model on the test data is approximately `78.21%`. This means that the model correctly predicted whether a passenger survived or not in about 78.21% of cases in the test set. This is a decent accuracy score, suggesting that the model is fairly good at predicting survival on the Titanic based on the features provided. However, there may still be room for improvement, for example by tuning the parameters of the RandomForestClassifier or by engineering additional features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "In this example, we start by loading the Titanic dataset from Seaborn using sns.load_dataset('titanic'). We then select the relevant features and target variable (survived) to train our model. Next, we split the data into training and test sets using train_test_split from scikit-learn.\n",
    "\n",
    "The pipeline is created using the Pipeline class from scikit-learn. It consists of three steps:\n",
    "\n",
    "1. Data preprocessing step: The SimpleImputer is used to handle missing values by replacing them with the most frequent value in each column.\n",
    "\n",
    "2. Feature encoding step: The OneHotEncoder is used to encode categorical variables (`sex and embarked`) as binary features.\n",
    "\n",
    "3. Model training step: The RandomForestClassifier is used as the machine learning model for classification.\n",
    "\n",
    "We then fit the pipeline on the training data using pipeline.fit(X_train, y_train). Afterward, we make predictions on the test data using pipeline.predict(`X_test`).\n",
    "\n",
    "Finally, we calculate the accuracy score by comparing the predicted values (`y_pred`) with the actual values (`y_test`).\n",
    "\n",
    "Note that you may need to install Seaborn (`pip install seaborn`) if it's not already installed in your environment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Hyperparamter Tunning in Pipeline**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning in a pipeline involves optimizing the hyperparameters of the different steps in the pipeline to find the best combination that maximizes the model's performance. Here's an example of hyperparameter tuning in a pipeline and selecting the best model on the Titanic dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8212290502793296\n",
      "Best Hyperparameters: {'model__max_depth': 30, 'model__min_samples_split': 5, 'model__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Titanic dataset from Seaborn\n",
    "titanic_data = sns.load_dataset('titanic')\n",
    "\n",
    "# Select features and target variable\n",
    "X = titanic_data[['pclass', 'sex', 'age', 'fare', 'embarked']]\n",
    "y = titanic_data['survived']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ('model', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "hyperparameters = {\n",
    "    'model__n_estimators': [100, 200, 300, 500],\n",
    "    'model__max_depth': [None, 5, 10, 30],\n",
    "    'model__min_samples_split': [2, 5, 10, 15]\n",
    "}\n",
    "\n",
    "# Perform grid search cross-validation\n",
    "grid_search = GridSearchCV(pipeline, hyperparameters, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is using a machine learning pipeline to preprocess the Titanic dataset, perform `hyperparameter tuning using grid search cross-validation`, and train a `RandomForestClassifier`. Here's a breakdown of the code:\n",
    "\n",
    "- The Titanic dataset is loaded and the features (`X`) and target variable (`y`) are selected.\n",
    "\n",
    "- The data is split into training and test sets using `train_test_split`.\n",
    "\n",
    "- A pipeline is defined that first imputes missing values with the most frequent value, applies one-hot encoding, and then trains a `RandomForestClassifier`.\n",
    "\n",
    "- A dictionary of hyperparameters to tune is defined. The keys of the dictionary are the hyperparameters and the values are the possible values for each hyperparameter.\n",
    "\n",
    "- Grid search cross-validation is performed using `GridSearchCV`. This function performs cross-validation for each combination of hyperparameters and returns the best model.\n",
    "\n",
    "- The best model is used to make predictions on the test data.\n",
    "\n",
    "- The accuracy of the predictions is calculated using `accuracy_score` and printed out.\n",
    "\n",
    "**Observations from the Output:**\n",
    "> The output shows that the accuracy of the best model on the test data is approximately `82.12%`. This means that the best model correctly predicted whether a passenger survived or not in about 82.12% of cases in the test set. This is a good accuracy score, suggesting that the model is quite good at predicting survival on the Titanic based on the features provided.\n",
    "\n",
    "> The output also shows that the `best hyperparameters` for the RandomForestClassifier are a `maximum depth of 30`, a `minimum number of samples required to split an internal node of 5`, and `100 trees` in the forest. These hyperparameters resulted in the highest cross-validation accuracy score during the grid search."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Best `Model Selection` in Pipeline**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the best model when using multiple models in a pipeline, you can use techniques like cross-validation and evaluation metrics to compare their performance. Here's an example of how to accomplish this on the Titanic dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Cross-validation Accuracy: 0.7991529597163399\n",
      "Test Accuracy: 0.8324022346368715\n",
      "\n",
      "Model: Gradient Boosting\n",
      "Cross-validation Accuracy: 0.8076135132473162\n",
      "Test Accuracy: 0.7988826815642458\n",
      "\n",
      "Best Model: Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
      "                ('encoder', OneHotEncoder(handle_unknown='ignore')),\n",
      "                ('model', RandomForestClassifier(random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Titanic dataset from Seaborn\n",
    "titanic_data = sns.load_dataset('titanic')\n",
    "\n",
    "# Select features and target variable\n",
    "X = titanic_data[['pclass', 'sex', 'age', 'fare', 'embarked']]\n",
    "y = titanic_data['survived']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a list of models to evaluate\n",
    "models = [\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(random_state=42))\n",
    "]\n",
    "\n",
    "best_model = None\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate over the models and evaluate their performance\n",
    "for name, model in models:\n",
    "    # Create a pipeline for each model\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore')),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=5)\n",
    "    \n",
    "    # Calculate mean accuracy\n",
    "    mean_accuracy = scores.mean()\n",
    "    \n",
    "    # Fit the pipeline on the training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Print the performance metrics\n",
    "    print(\"Model:\", name)\n",
    "    print(\"Cross-validation Accuracy:\", mean_accuracy)\n",
    "    print(\"Test Accuracy:\", accuracy)\n",
    "    print()\n",
    "    \n",
    "    # Check if the current model has the best accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = pipeline\n",
    "\n",
    "# Retrieve the best model\n",
    "print(\"Best Model:\", best_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is using a machine learning pipeline to preprocess the Titanic dataset, `evaluate two different models` (RandomForestClassifier and GradientBoostingClassifier), and `select the best model based on test accuracy`. Here's a breakdown of the code:\n",
    "\n",
    "- The Titanic dataset is loaded and the features (`X`) and target variable (`y`) are selected.\n",
    "\n",
    "- The data is split into training and test sets using `train_test_split`.\n",
    "\n",
    "- A list of models to evaluate is defined. Each model is represented as a tuple containing the name of the model and the model itself.\n",
    "\n",
    "- The code then iterates over the list of models. For each model, it creates a pipeline that first imputes missing values with the most frequent value, applies one-hot encoding, and then trains the model.\n",
    "\n",
    "- The pipeline is evaluated using 5-fold cross-validation on the training data. The mean cross-validation accuracy is calculated and printed out.\n",
    "\n",
    "- The pipeline is then fitted on the entire training data and used to make predictions on the test data. The test accuracy is calculated and printed out.\n",
    "\n",
    "- If the test accuracy of the current model is higher than the best accuracy seen so far, the current model is updated as the best model.\n",
    "\n",
    "- After all models have been evaluated, the best model is printed out.\n",
    "\n",
    "**Observations from the Output:**\n",
    "> The output shows that the `RandomForestClassifier` has a cross-validation accuracy of approximately `79.92%` and a test accuracy of approximately `83.24%`, while the `GradientBoostingClassifier` has a cross-validation accuracy of approximately `80.76%` and a test accuracy of approximately `79.89%`. \n",
    "\n",
    "> Even though the GradientBoostingClassifier has a slightly higher cross-validation accuracy, the **`RandomForestClassifier`** has a higher test accuracy, so it is selected as the best model. This shows that cross-validation accuracy is not always indicative of test accuracy, and it's important to evaluate models on a separate test set that was not used during training or cross-validation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Adding more Models in the Same Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Cross-validation Accuracy: 0.7991529597163399\n",
      "Test Accuracy: 0.8379888268156425\n",
      "\n",
      "Model: Gradient Boosting\n",
      "Cross-validation Accuracy: 0.8061952132374668\n",
      "Test Accuracy: 0.7988826815642458\n",
      "\n",
      "Model: Support Vector Machine\n",
      "Cross-validation Accuracy: 0.8160248202501723\n",
      "Test Accuracy: 0.8044692737430168\n",
      "\n",
      "Model: Logistic Regression\n",
      "Cross-validation Accuracy: 0.7977839062346105\n",
      "Test Accuracy: 0.8100558659217877\n",
      "\n",
      "Best Model: Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
      "                ('encoder', OneHotEncoder(handle_unknown='ignore')),\n",
      "                ('model', RandomForestClassifier(random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Titanic dataset from Seaborn\n",
    "titanic_data = sns.load_dataset('titanic')\n",
    "\n",
    "# Select features and target variable\n",
    "X = titanic_data[['pclass', 'sex', 'age', 'fare', 'embarked']]\n",
    "y = titanic_data['survived']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a list of models to evaluate\n",
    "models = [\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(random_state=42)),\n",
    "    ('Support Vector Machine', SVC(random_state=42)),\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42))\n",
    "]\n",
    "\n",
    "best_model = None\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate over the models and evaluate their performance\n",
    "for name, model in models:\n",
    "    # Create a pipeline for each model\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore')),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=5)\n",
    "    \n",
    "    # Calculate mean accuracy\n",
    "    mean_accuracy = scores.mean()\n",
    "    \n",
    "    # Fit the pipeline on the training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Print the performance metrics\n",
    "    print(\"Model:\", name)\n",
    "    print(\"Cross-validation Accuracy:\", mean_accuracy)\n",
    "    print(\"Test Accuracy:\", accuracy)\n",
    "    print()\n",
    "    \n",
    "    # Check if the current model has the best accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = pipeline\n",
    "\n",
    "# Retrieve the best model\n",
    "print(\"Best Model:\", best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is using a `machine learning pipeline` to preprocess the Titanic dataset, `evaluate four different models` (RandomForestClassifier, GradientBoostingClassifier, Support Vector Machine, and Logistic Regression), and `select the best model based on test accuracy`. Here's a breakdown of the code:\n",
    "\n",
    "- The Titanic dataset is loaded and the features (`X`) and target variable (`y`) are selected.\n",
    "\n",
    "- The data is split into training and test sets using `train_test_split`.\n",
    "\n",
    "- A list of models to evaluate is defined. Each model is represented as a tuple containing the name of the model and the model itself.\n",
    "\n",
    "- The code then iterates over the list of models. For each model, it creates a pipeline that first imputes missing values with the most frequent value, applies one-hot encoding, and then trains the model.\n",
    "\n",
    "- The pipeline is evaluated using 5-fold cross-validation on the training data. The mean cross-validation accuracy is calculated and printed out.\n",
    "\n",
    "- The pipeline is then fitted on the entire training data and used to make predictions on the test data. The test accuracy is calculated and printed out.\n",
    "\n",
    "- If the test accuracy of the current model is higher than the best accuracy seen so far, the current model is updated as the best model.\n",
    "\n",
    "- After all models have been evaluated, the best model is printed out.\n",
    "\n",
    "**Observations from the Output:**\n",
    "> The output shows that the `RandomForestClassifier` has the highest test accuracy of approximately `83.80%`, so it is selected as the best model. This shows that even though other models might have higher cross-validation accuracy (like the Support Vector Machine), the RandomForestClassifier performs best on the unseen test data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
