{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Random Forest**\n",
    "> Random Forest is a `supervised learning algorithm`. Like you can already see from it’s name, it creates a forest and makes it somehow random. `The „forest“ it builds, is an ensemble of Decision Trees`, most of the time trained with the “bagging” method. The general idea of the bagging method is that a combination of learning models increases the overall result.\n",
    "\n",
    "To say it in simple words: Random forest builds multiple decision trees and merges them together to get a more accurate and stable prediction.\n",
    "- Random forest is a type of ensemble method, specifically a `bagging method`. \n",
    "- It is used for classification and regression problems.\n",
    "- Bagging methods form a class of algorithms which build several instances of a black-box model on random subsets of the data and then aggregate their individual predictions to form a final prediction. \n",
    "- These methods are used as a way to `reduce the variance` of a base estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **How does Random Forest work?**\n",
    "- **Bootstrap Aggregating (Bagging)**: Random Forest creates multiple decision trees using bagging. It randomly selects samples from the dataset with replacement and builds a decision tree for each sample.\n",
    "- **Random Feature Selection**: In each split during the tree construction, a random subset of features is considered. This randomness helps in making the model more robust and prevents overfitting.\n",
    "- **Aggregation of Results**: For classification, the most voted class becomes the model's prediction. For regression, it averages the outputs of different trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Key Features of Random Forest Algorithm:**\n",
    "- **Robustness**: It's less prone to overfitting because it combines the results of many decision trees.\n",
    "- **Handling Non-linearity**: It can handle non-linear features and relationships with its non-linear structure.\n",
    "- **Feature Importance**: It provides insights into which features are more important in making predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Advantages of Random Forest:**\n",
    "- **High Accuracy**: Often provides high accuracy in predictive tasks.\n",
    "- **Verstality**: Can be used for both classification and regression tasks.\n",
    "- **Ease of use**: It's easy to use and requires very few hyperparameters to set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Applications of Random Forest:**\n",
    "- **Banking**: It is used for identifying loyal customers and finding fraud customers.\n",
    "- **Medicine**: It is used to identify the correct combination of components to validate the medicine.\n",
    "- **Stock Market**: It is used to identify the stock behavior and the expected loss or profit by purchasing the stocks.\n",
    "- **E-commerce**: It is used to identify whether the customer will actually like the product or not.\n",
    "- **Agriculture**: It is used to identify the diseases of plants.\n",
    "- **Healthcare**: It is used to identify the correct combination of components to validate the medicine.\n",
    "- **Marketing**: It is used to identify the potential customers for the products.\n",
    "- **Image Classification**: It is used to classify the images into different categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Best Prctices and Considerations:**\n",
    "- **Number of Trees**: More trees can can increase accuracy but also computational cost.\n",
    "- **Depth of Trees**: Deeper trees can capture more information but might lead to overfitting.\n",
    "- **Feature Selection**: It's important to ensure that the features are relevant and of good quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Challenges of Random Forest:**\n",
    "- **Complexity**: It can be computationally expensive and slow to train.\n",
    "- **Model Interpretability**: As a complex model, it's often more difficult to interpret than simpler models.\n",
    "- **Computationally Intensive**: Can be resource-intensive, espcially with large datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
