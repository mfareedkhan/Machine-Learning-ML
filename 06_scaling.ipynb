{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Transformation:**\n",
    "> Data transformation in the context of data preprocessing refers to the process of `changing the format`, `structure`, or `val`ues of data to prepare it for analysis. \n",
    "\n",
    "This can involve a wide range of activities, including:\n",
    "\n",
    "**1. Standardization**: Rescaling data to have a `mean` of `0` and a `standard deviation` of `1`. \n",
    "- This is often used when the algorithm you're using does make assumptions about your data having a Gaussian distribution, such as linear regression, logistic regression, and linear discriminant analysis.\n",
    "\n",
    "**2. Normalization**: Scaling numerical data to fall within a certain range, often `0` to `1`, to allow for fair comparison between different features.\n",
    "\n",
    "**3. Encoding categorical variables**: `Converting categorical` variables into a format that can be used by machine learning algorithms, such as one-hot encoding or ordinal encoding.\n",
    "\n",
    "**4. Discretization**: Converting `continuous data` into `discrete bins`, for example, converting age into age groups.\n",
    "\n",
    "**5. Handling datetime variables**: Extracting components of date-time variables, such as the year, month, day, or day of the week, or calculating the duration between dates.\n",
    "\n",
    "**6. Feature extraction**: `Creating new features from existing ones`, such as creating a \"total income\" feature from \"monthly income\" and \"number of months\".\n",
    "\n",
    "These transformations help to make the data more suitable for analysis and can improve the performance of machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Linear Transformation:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.1 Standardization / Standard Scaling:**\n",
    "\n",
    "`Standard scaling` is a method of scaling the data such that the distribution of the data is centered around 0, with a standard deviation of 1. This is done by subtracting the mean of the data from each data point and then dividing by the standard deviation of the data. This is a very common method of scaling data, and is used in many machine learning algorithms.\n",
    "\n",
    "The formula is as follows:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "Where:\n",
    "- Z is the standardized value,\n",
    "- X is the original value,\n",
    "- μ is the mean of the feature,\n",
    "- σ is the standard deviation of the feature.\n",
    "\n",
    "**Types**:\n",
    "\n",
    "There's only one type of standard scaling, but it's worth noting that similar techniques include `Min-Max scaling` (normalization), which scales data to a specified range (usually 0 to 1), `MaxAbsScalar`, which scale each feature by its maximum absolue value, and `Robust scaling`, which scales data according to the interquartile range and is less affected by outliers.\n",
    "\n",
    "**Summary:** (for linear data)\n",
    "- Standardization / Standard Scaling: `-3 to +3`  (can handle negative values)\n",
    "- MinMaxSacaler: `0 to 1 `                        (can handle only positive values)\n",
    "- MaxAbsScalar: `-1 to +1 `                       (can handlenegative values)\n",
    "- RobustScalar: \n",
    "\n",
    "**When to Use**:\n",
    "\n",
    "- Standard scaling is used when the algorithm you're using does make assumptions about your data having a Gaussian distribution, such as linear regression, logistic regression, and linear discriminant analysis. \n",
    "- It's also useful when features in your dataset have different scales but need to be on the same scale for the algorithm to perform well, such as in support vector machines (SVM) or k-nearest neighbors (KNN).\n",
    "\n",
    "**Limitations**:\n",
    "\n",
    "- Standard scaling does not normalize the distribution of the data, so it might not be suitable for data that does not follow a Gaussian distribution / Normal Distribution.\n",
    "- It's sensitive to outliers. If there are outliers in the data, the scaled data will also have outliers.\n",
    "- The interpretability of the features is lost after scaling. The scaled features are hard to interpret in their original context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **For Non-Parametric Distribution:**\n",
    "- **Quantile Transformer:** transformer into linear transformation \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.1 Using SKLearn Library:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>170</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>175</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>180</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>185</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height  weight\n",
       "0   25     165      55\n",
       "1   30     170      60\n",
       "2   35     175      65\n",
       "3   40     180      70\n",
       "4   45     185      75"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make an example dataset\n",
    "df = {\n",
    "    'age': [25,30,35,40,45],\n",
    "    'height': [165,170,175,180,185],\n",
    "    'weight': [55,60,65,70,75]\n",
    "}\n",
    "\n",
    "# conver this data to pandas datafram\n",
    "df = pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Standard Scaling:**\n",
    "(-3 to +3)\n",
    "\n",
    "> Standard Scaler is a preprocessing technique used in machine learning to standardize the dataset’s features to have a mean of 0 and a standard deviation of 1. It is also known as `Z-score normalization`.\n",
    "\n",
    "The `formula` for standard scaling is:\n",
    "\n",
    "Z = (X - μ) / σ\n",
    "\n",
    "Where:\n",
    "- Z is the standardized value,\n",
    "- X is the original value,\n",
    "- μ is the mean of the feature,\n",
    "- σ is the standard deviation of the feature.\n",
    "\n",
    "**When to use?**\n",
    "- Standard Scaler is used when the features of the input dataset have large differences between their ranges, or when a standard normal distribution is assumed based on the machine learning algorithm used. \n",
    "- Algorithms like Support Vector Machines (SVM), Linear Regression, Logistic Regression, and K-Nearest Neighbors (KNN) perform better when data is standardized. \n",
    "\n",
    "However, it's important to note that Standard Scaler is sensitive to outliers, so if the dataset contains significant outliers, another scaling method may be more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.414214</td>\n",
       "      <td>-1.414214</td>\n",
       "      <td>-1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age    height    weight\n",
       "0 -1.414214 -1.414214 -1.414214\n",
       "1 -0.707107 -0.707107 -0.707107\n",
       "2  0.000000  0.000000  0.000000\n",
       "3  0.707107  0.707107  0.707107\n",
       "4  1.414214  1.414214  1.414214"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the scalar\n",
    "scalar = StandardScaler()\n",
    "\n",
    "# fit the scalar on data\n",
    "scaled_df = scalar.fit_transform(df)\n",
    "scaled_df\n",
    "# convert this data into a pandas dataframe\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=df.columns)\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. MinMaxScalar:**\n",
    "(0 to 1)\n",
    "> MinMax Scaler is a data preprocessing technique used to `normalize the range of independent variables` or features of data. It scales and translates each feature individually such that it is in the given range on the training set, typically between 0 and 1, or so that the maximum absolute value of each feature is scaled to unit size.\n",
    "\n",
    "The `formula` for MinMax Scaler is:\n",
    "\n",
    "```\n",
    "X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "X_scaled = X_std * (max - min) + min\n",
    "```\n",
    "\n",
    "Where:\n",
    "- `X` is the original feature vector,\n",
    "- `X.min(axis=0)` is the minimum value of the feature,\n",
    "- `X.max(axis=0)` is the maximum value of the feature,\n",
    "- `X_std` is the standard deviation of the feature,\n",
    "- `X_scaled` is the scaled feature.\n",
    "\n",
    "**When to use?**\n",
    "- MinMax Scaler is used when the distribution is not Gaussian or the standard deviation is very small. \n",
    "- It is also used when preserving zero entries in sparse data is important. \n",
    "- However, it is sensitive to outliers, so if the dataset contains significant outliers, MinMax Scaler might not be the best choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  height  weight\n",
       "0  0.00    0.00    0.00\n",
       "1  0.25    0.25    0.25\n",
       "2  0.50    0.50    0.50\n",
       "3  0.75    0.75    0.75\n",
       "4  1.00    1.00    1.00"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the scalar\n",
    "scalar = MinMaxScaler()\n",
    "\n",
    "# fit the scalar on data\n",
    "scaled_df = scalar.fit_transform(df)\n",
    "# convert this data into a pandas dataframe\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=df.columns)\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. MaxAbsScalar:**\n",
    "(-1 to 1)\n",
    "> MaxAbsScaler is a data preprocessing technique that scales each feature by its `maximum absolute value`. This is a type of scaling that does not shift/center the data, and thus it does not destroy any sparsity.\n",
    "\n",
    "The `formula` for MaxAbsScaler is:\n",
    "\n",
    "\n",
    "X_scaled = X / abs(X.max)\n",
    "\n",
    "\n",
    "Where:\n",
    "- `X_scaled` is the scaled feature,\n",
    "- `X` is the original feature,\n",
    "- `abs(X.max)` is the maximum absolute value of the feature.\n",
    "\n",
    "**When to use?**\n",
    "- MaxAbsScaler is meant for data that is already centered or sparse data. \n",
    "- It does not shift the data, and thus does not destroy any sparsity. \n",
    "- This makes it a suitable technique for handling sparse datasets where zero entries need to be preserved. \n",
    "- It's also useful when the dataset contains features with varying scales but does not contain large outliers, as MaxAbsScaler does not reduce the impact of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age    height    weight\n",
       "0  0.555556  0.891892  0.733333\n",
       "1  0.666667  0.918919  0.800000\n",
       "2  0.777778  0.945946  0.866667\n",
       "3  0.888889  0.972973  0.933333\n",
       "4  1.000000  1.000000  1.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the scalar\n",
    "scalar = MaxAbsScaler()\n",
    "\n",
    "# fit the scalar on data\n",
    "scaled_df = scalar.fit_transform(df)\n",
    "scaled_df\n",
    "# convert this data into a pandas dataframe\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=df.columns)\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. RobustScalar:**\n",
    "(-1 to 1)\n",
    "> RobustScaler is a preprocessing technique that scales features using statistics that are robust to outliers. This method removes the median and scales the data according to the Interquartile Range (`IQR`). The IQR is the range between the 1st quartile (25th quantile) and the 3rd quartile (75th quantile).\n",
    "\n",
    "The `formula` for RobustScaler is:\n",
    "\n",
    "\n",
    "X_scaled = (X - Q1) / (Q3 - Q1)\n",
    "\n",
    "\n",
    "Where:\n",
    "- `X_scaled` is the scaled feature,\n",
    "- `X` is the original feature,\n",
    "- `Q1` is the first quartile of the feature,\n",
    "- `Q3` is the third quartile of the feature.\n",
    "\n",
    "**When to use?**\n",
    "- RobustScaler is used when you want to reduce the effects of outliers, as it uses the Interquartile Range, which is not influenced by outliers. \n",
    "- It's a good choice for data that contains outliers or when standardizing distribution is not the aim. \n",
    "- It's also useful when the data is not normally distributed, as it does not distort the relative distances between the various feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height  weight\n",
       "0 -1.0    -1.0    -1.0\n",
       "1 -0.5    -0.5    -0.5\n",
       "2  0.0     0.0     0.0\n",
       "3  0.5     0.5     0.5\n",
       "4  1.0     1.0     1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# import the scalar\n",
    "scalar = RobustScaler()\n",
    "\n",
    "# fit the scalar on data\n",
    "scaled_df = scalar.fit_transform(df)\n",
    "scaled_df\n",
    "# convert this data into a pandas dataframe\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=df.columns)\n",
    "scaled_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
