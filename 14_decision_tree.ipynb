{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Decision Tree Algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is a Decision Tree?**\n",
    "> A decision tree is a flowchart-like tree structure where an internal node represents a feature(or attribute), the branch represents a decision rule, and each leaf node represents the outcome. The topmost node in a decision tree is known as the root node. It learns to partition on the basis of the attribute value.\n",
    "**Lay man example of Decision Tree:**\n",
    "> Suppose you want to predict whether a person is fit or unfit, given their information like age, eating habits, and physical activity. The decision tree algorithm will start by finding the root node (the best feature to split the dataset). The root node is then split into decision nodes, which are further split into leaf nodes. The leaf node is the prediction of the decision tree.\n",
    "\n",
    "**Classification Tree (`Categorical Output`)**: Decision Tree which is used to solve classification problems is called a Classification Tree. In a classification tree, we try to use the tree to classify the input into a category. For example, if we want to classify whether a person is fit or unfit, the decision tree will classify the person as fit or unfit based on input variables.\n",
    "\n",
    "**Regression Tree (`Continuous Output`)**: Decision Tree which is used to solve regression problems is called a Regression Tree. In a regression tree, we try to use the tree to predict the output value. For example, if we want to predict the sales of a company, the decision tree will predict the sales based on input variables.\n",
    "\n",
    "**Image for Classficication and Regression Tree:**\n",
    "\n",
    "![image](\"C:/Users/Hp/Desktop/Data-Science-Codanics/07_machine_learning/decision_tree_for_heart_attack_prevention_2140bd762d.png\")\n",
    "\n",
    "### **Elements of Decision Tree:**\n",
    "\n",
    "**Node**:  Point where the data is split. Node in a decision tree represents an attribute. There are two types of nodes:\n",
    "- `Decision Node`: When a sub-node splits into further sub-nodes, then it is called the decision node.\n",
    "    - It gives you final decision based on the input features.\n",
    "    - Final imput might be numeric (regression) or categorical (classofication).\n",
    "- `Leaf/ Terminal Node`: Nodes do not split is called Leaf or Terminal node.\n",
    "\n",
    "**Root Node**: The top node where the data is split is called the root node. It represents the entire population or sample and this further gets divided into two or more homogeneous sets. \n",
    "- maximum impurity at this level. \n",
    "\n",
    "**Branch**: A sub-section of the entire tree is called the branch or sub-tree.\n",
    "\n",
    "**Splitting**: It is a process of dividing a node into two or more sub-nodes.\n",
    "\n",
    "**Pruning**: When we remove sub-nodes of a decision node, this process is called pruning. You can say the opposite process of splitting.It is helpful to reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Entropy, Gini Impurity and Information Gain Theory:**\n",
    "\n",
    "#### **Entropy**: \n",
    "> Measure of randomness or uncertainty. It is used to measure the impurity or randomness in the data. \n",
    "- It is used to decide how a decision tree can split the data. \n",
    "- It is a measure of impurity in a bunch of examples. \n",
    "- If entropy is zero then all elements are of the same class, indicating no disorder\n",
    "- If entropy is one when all elements are of different classes, indicating maximum disorder.\n",
    "\n",
    "The `formula` for entropy is:\n",
    "\n",
    "$$\n",
    "Entropy = -\\sum_{i=1}^{n} p_i \\cdot \\log_2(p_i)\n",
    "$$    \n",
    "    Where, $p_i$ is the probability of finding an element of class i.\n",
    "\n",
    "#### **Information Gain**: \n",
    "> It measured the reduction in entropy or impurity in the target variable brought about by partitioning the data based on a certain attribute. \n",
    "- It is used in decision trees to decide the order of attribute nodes.\n",
    "- It is the difference between the entropy of the dataset before the split and after the split.\n",
    "- `A higher information gain means a higher reduction in entropy, suggesting a better split.`\n",
    "\n",
    "The `formula` for Information Gain is:\n",
    "\n",
    "$$\n",
    "Information\\ Gain = Entropy(Parent) - \\sum_{i=1}^{n} \\left( \\frac{|D_v|}{|D|} \\cdot Entropy(Child_i) \\right)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $Entropy(Parent)$ is the entropy of the parent node,\n",
    "- $Entropy(Child_i)$ is the entropy of the $i$-th child node,\n",
    "- $|D_v|$ is the number of instances that reach child node $i$,\n",
    "- $|D|$ is the total number of instances at the parent node,\n",
    "- The sum is over all child nodes of the parent node.\n",
    "\n",
    "\n",
    "The information gain is based on the decrease in entropy after a dataset is split on an attribute. Constructing a decision tree is all about finding attribute that returns the highest information gain (i.e., the most homogeneous branches).\n",
    "\n",
    "#### **Gini Impurity**: \n",
    "> Gini impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset. \n",
    "\n",
    "- Gini impurity is zero when all the elements are of a certain class, indicating purity.\n",
    "- As the distribution of classes approaches uniform, Gini impurity approaches its maximum value.\n",
    "\n",
    "The `formula` for Gini Impurity is:\n",
    "$$\n",
    "Gini\\ Impurity (S) = 1 - \\sum_{i=1}^{n} p_i^2\n",
    "$$\n",
    "Where, $p_i$ is the probability of finding an element of class i."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparison between Entropy and Gini Impurity:**\n",
    "\n",
    "| Criteria | Entropy | Gini Impurity |\n",
    "| --- | --- | --- |\n",
    "| **Definition** | Entropy is a measure of disorder or uncertainty. It is used to calculate the homogeneity of the input set. | Gini Impurity is a measure of misclassification, which applies in a multi-class classifier context. |\n",
    "| **Computation** | Computationally, entropy is more intensive as it involves logarithmic calculations. | Gini Impurity is less computationally intensive as it involves only squaring and addition/subtraction. |\n",
    "| **Sensitivity** | Entropy is more sensitive towards changes in the node probabilities. | Gini Impurity is less sensitive to changes in the node probabilities. |\n",
    "| **Bias** | Entropy might be slightly biased towards multi-level attributes. | Gini Impurity is unbiased as it tends to isolate the most frequent class in its own branch of the tree. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Summary:**\n",
    "The **Entropy** and **Information Gain** method `focuses on purity and impurity in a node`. The **Gini** Index or Impurity `measures the probability for a random instance being misclassified when chosen randomly`. The lower the Gini Index, the better the lower the likelihood of misclassification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Import Libarary:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Sample Dataset:**\n",
    "- Let's say we have a dataset with two classes, A and B and A has 4 elements and B has 6 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Data for the two classes\n",
    "\n",
    "n_A = 4  # Number of elements in class A\n",
    "n_B = 6  # Number of elements in class B\n",
    "total = n_A + n_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Let's Calculate the Proportion:**\n",
    "- The proportion of A is 4/10 and the proportion of B is 6/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of A:  0.4\n",
      "Proportion of B:  0.6\n"
     ]
    }
   ],
   "source": [
    "# let's calculate the proportions\n",
    "p_A = n_A / total  # 4/10 = 0.4\n",
    "p_B = n_B / total  # 6/10 = 0.6\n",
    "\n",
    "# print the proportions\n",
    "print(\"Proportion of A: \", p_A)\n",
    "print(\"Proportion of B: \", p_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Let's Undertsand the important Metrics of Decision Tree Algorithm.**\n",
    "1. **Entropy**\n",
    "2. **Gini Impurity**\n",
    "3. **Information Gain** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Let's Calculate the Entropy:**\n",
    "- The entropy of the dataset is calculated as:\n",
    "- $Entropy = -\\sum_{i=1}^{n} p_i \\cdot \\log_2(p_i)$\n",
    "- $Entropy = -\\left( \\frac{4}{10} \\cdot \\log_2\\left(\\frac{4}{10}\\right) + \\frac{6}{10} \\cdot \\log_2\\left(\\frac{6}{10}\\right) \\right)$\n",
    "- $Entropy = -\\left( \\frac{4}{10} \\cdot \\log_2\\left(\\frac{4}{10}\\right) + \\frac{6}{10} \\cdot \\log_2\\left(\\frac{6}{10}\\right) \\right)$\n",
    "- $Entropy = -\\left( 0.4 \\cdot \\log_2(0.4) + 0.6 \\cdot \\log_2(0.6) \\right)$\n",
    "- $Entropy = -\\left( 0.4 \\cdot (-0.528) + 0.6 \\cdot (-0.442) \\right)$\n",
    "- $Entropy = -\\left( -0.2112 - 0.2652 \\right)$\n",
    "- $Entropy = -\\left( -0.4764 \\right)$\n",
    "- $Entropy = 0.4764$\n",
    "- The entropy of the dataset is 0.97."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy:  0.9709505944546686\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Entropy\n",
    "# Entropy is a measure of uncertainty\n",
    "entropy = -p_A * math.log2(p_A) - p_B * math.log2(p_B)\n",
    "print(\"Entropy: \", entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Entropy = 0.97` shows that the dataset is `highly impure`. \n",
    "- Entropy = 0 means the dataset is `pure` and Entropy = 1 means the dataset is `completely impure`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. Let's Calculate the Gini Impurity:**\n",
    "- The Gini impurity of the dataset is calculated as:\n",
    "- $Gini\\ Impurity (S) = 1 - \\sum_{i=1}^{n} p_i^2$\n",
    "- $Gini\\ Impurity (S) = 1 - \\left( \\left(\\frac{4}{10}\\right)^2 + \\left(\\frac{6}{10}\\right)^2 \\right)$\n",
    "- $Gini\\ Impurity (S) = 1 - \\left( \\left(\\frac{4}{10}\\right)^2 + \\left(\\frac{6}{10}\\right)^2 \\right)$\n",
    "- $Gini\\ Impurity (S) = 1 - \\left( \\left(\\frac{4}{10}\\right)^2 + \\left(\\frac{6}{10}\\right)^2 \\right)$\n",
    "- $Gini\\ Impurity (S) = 1 - \\left( \\left(\\frac{16}{100}\\right) + \\left(\\frac{36}{100}\\right) \\right)$\n",
    "- $Gini\\ Impurity (S) = 1 - \\left( 0.16 + 0.36 \\right)$\n",
    "- $Gini\\ Impurity (S) = 1 - 0.52$\n",
    "- $Gini\\ Impurity (S) = 0.48$\n",
    "- The Gini impurity of the dataset is 0.48."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Impurity:  0.48\n"
     ]
    }
   ],
   "source": [
    "# gini impurity\n",
    "# Gini impurity is a measure of misclassification\n",
    "gini = 1- p_A**2 - p_B**2\n",
    "print(\"Gini Impurity: \", gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Gini Impurity = 0.48` shows that the dataset is `moderate impure`.\n",
    "- Gini Impurity = 0 means the dataset is `pure` and Gini Impurity = 1 means the dataset is `completely impure`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6. Let's Calculate the Information Gain:**\n",
    "- The information gain is the difference between the entropy of the dataset before the split and the sum of the entropy of each group after the split.\n",
    "- $Information\\ Gain = Entropy(Parent) - \\sum_{i=1}^{n} \\left( \\frac{|D_v|}{|D|} \\cdot Entropy(Child_i) \\right)$\n",
    "- $Information\\ Gain = 0.97 - \\left( \\frac{4}{10} \\cdot 0.811 + \\frac{6}{10} \\cdot 0.971 \\right)$\n",
    "- $Information\\ Gain = 0.97 - \\left( 0.3244 + 0.5826 \\right)$\n",
    "- $Information\\ Gain = 0.97 - 0.907$\n",
    "- $Information\\ Gain = 0.063$\n",
    "- The information gain of the dataset is 0.063."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Information Gain\n",
    "# Assuming a split on some feature divides the dataset into two subsets\n",
    "# Subset 1: 2 elements of A, 3 of B\n",
    "# Subset 2: 2 elements of A, 3 of B\n",
    "# Entropy and size for each subset\n",
    "n_1_A, n_1_B = 2, 3\n",
    "n_2_A, n_2_B = 2, 3\n",
    "\n",
    "p_1_A = n_1_A / (n_1_A + n_1_B)\n",
    "p_1_B = n_1_B / (n_1_A + n_1_B)\n",
    "entropy_1 = -p_1_A * math.log2(p_1_A) - p_1_B * math.log2(p_1_B) if p_1_A and p_1_B else 0\n",
    "\n",
    "p_2_A = n_2_A / (n_2_A + n_2_B)\n",
    "p_2_B = n_2_B / (n_2_A + n_2_B)\n",
    "entropy_2 = -p_2_A * math.log2(p_2_A) - p_2_B * math.log2(p_2_B) if p_2_A and p_2_B else 0\n",
    "\n",
    "# Calculating information gain\n",
    "info_gain = entropy - ((n_1_A + n_1_B) / total * entropy_1 + (n_2_A + n_2_B) / total * entropy_2)\n",
    "print(\"Information Gain: \", info_gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Information Gain = 0.063` shows that the dataset is `highly impure`.\n",
    "- The information gain from the chosen split is 0.0. This result implies that the split did not reduce the entropy or disorder of the dataset. In other words, the split did not add any additional information that could help distinguish between classes A and B more effectively than before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These metrics provide insight into the nature of the dataset and the effectiveness of potential splits when constructing a decision tree. In practical applications, you would use these calculations to choose the best feature and split at each node in the tree to maximize the purity of the subsets created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **Decision Tree `Classification` Example in Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Import Libraries:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Load the 'Titanic' dataset from Seaborn Library:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Data Preprocessing:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.1 Checking for Missing Values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deck           688\n",
       "age            177\n",
       "embarked         2\n",
       "embark_town      2\n",
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the above output, we can see that the columns 'deck', 'age', 'embarked', and 'embark_town' contains missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.2 Let's Drop / Impute the above Columns:**\n",
    "- Let's drop the 'deck' column from the dataset.\n",
    "- Let's impute the 'age' and 'fare' columns with the median value.\n",
    "- Let's impute the 'embarked_town' and 'embarked' columns with the mode value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop deck column\n",
    "df.drop('deck', axis=1, inplace=True)\n",
    "\n",
    "# Impute missing values of age, and fare using median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df[['age', 'fare']] = imputer.fit_transform(df[['age', 'fare']])\n",
    "\n",
    "# Impute missing values of embark and embarked_town using mode\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[['embark_town', 'embarked']] = imputer.fit_transform(df[['embark_town', 'embarked']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived       0\n",
       "pclass         0\n",
       "sex            0\n",
       "age            0\n",
       "sibsp          0\n",
       "parch          0\n",
       "fare           0\n",
       "embarked       0\n",
       "class          0\n",
       "who            0\n",
       "adult_male     0\n",
       "embark_town    0\n",
       "alive          0\n",
       "alone          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values again\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the output there is no missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          891 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     891 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  embark_town  891 non-null    object  \n",
      " 12  alive        891 non-null    object  \n",
      " 13  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(1), float64(2), int64(4), object(5)\n",
      "memory usage: 79.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. **Encode the Categorical and Object Variables using For Loop & LabelEncoder:** \n",
    "- We need to encode the categorical and object variables because the decision tree algorithm does not handle categorical data.\n",
    "- We can use the `LabelEncoder` class from the `sklearn.preprocessing` module to convert categorical data to numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorical and object variables using for loop and labelencoder\n",
    "le = LabelEncoder()\n",
    "for col in df.select_dtypes(include=['category', 'object']):\n",
    "    df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass  sex   age  sibsp  parch     fare  embarked  class  who  \\\n",
       "0         0       3    1  22.0      1      0   7.2500         2      2    1   \n",
       "1         1       1    0  38.0      1      0  71.2833         0      0    2   \n",
       "2         1       3    0  26.0      0      0   7.9250         2      2    2   \n",
       "3         1       1    0  35.0      1      0  53.1000         2      0    2   \n",
       "4         0       3    1  35.0      0      0   8.0500         2      2    1   \n",
       "\n",
       "   adult_male  embark_town  alive  alone  \n",
       "0        True            2      0  False  \n",
       "1       False            0      1  False  \n",
       "2       False            2      1   True  \n",
       "3       False            2      1  False  \n",
       "4        True            2      0   True  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. **Split the Data into Independent 'X' and Dependent 'Y' Variables:**\n",
    "- We need to split the dataset into independent and dependent variables. The independent variables are the variables that we want to use to make predictions, and the dependent variable is the variable that we want to predict.\n",
    "- The independent variables are stored in the 'X' variable, and the dependent variable is stored in the 'Y' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into X and y\n",
    "X = df.drop(['survived'], axis=1)\n",
    "y = df['survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. **Split the Data into 80% Training and 20% Testing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. **Create and Train the Decision Tree Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and train the model with pred\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. **Making Predictions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the model\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. **Evaluate the Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[105   0]\n",
      " [  0  74]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       105\n",
      "           1       1.00      1.00      1.00        74\n",
      "\n",
      "    accuracy                           1.00       179\n",
      "   macro avg       1.00      1.00      1.00       179\n",
      "weighted avg       1.00      1.00      1.00       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Observations from the Output:**\n",
    "| Metric | Class 0 | Class 1 | Overall | Observations |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| **Count** | 105 | 74 | 179 | The dataset contains more instances of class 0 than class 1. |\n",
    "| **Precision** | 1.00 | 1.00 | Weighted Avg: 1.00 | The model has perfect precision for both classes, meaning that every instance that it predicted as a certain class was actually that class. |\n",
    "| **Recall** | 1.00 | 1.00 | Macro Avg: 1.00 | The model has perfect recall for both classes, meaning that it identified all instances of each class correctly. |\n",
    "| **F1-Score** | 1.00 | 1.00 | Weighted Avg: 1.00 | The model has a perfect F1 score for both classes, indicating a perfect balance between precision and recall. |\n",
    "| **Support** | 105 | 74 | 179 | The actual occurrences of each class in the dataset match the count. |\n",
    "| **Confusion Matrix** | True Positives: 105<br>False Negatives: 0 | False Positives: 0<br>True Negatives: 74 | - | The model made no errors in its predictions. It correctly predicted all instances of both classes. |\n",
    "| **Accuracy** | - | - | 1.00 | The model has perfect accuracy, meaning it correctly predicted the class of every instance in the dataset. |\n",
    "\n",
    "Note: In the context of the confusion matrix, \"True Positives\" and \"True Negatives\" refer to correct predictions, while \"False Positives\" and \"False Negatives\" refer to incorrect predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. **Save the Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the decision tree classifier\n",
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(model, out_file='./saved_models/Decision_tree_01.dot', feature_names=X.columns, filled=True, rounded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Decision Tree `Regression` Example in Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2569.1690617816334\n"
     ]
    }
   ],
   "source": [
    "# 1. Split the data into independent (X) and Dependent (y) variables\n",
    "X = df.drop(['fare'], axis=1)  # Assuming we want to predict 'fare' for regression\n",
    "y = df['fare']\n",
    "\n",
    "# 2. Split the data into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Create and train the decision tree model\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Making Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 5. Evaluate the Model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# 6. Save the Model\n",
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(model, out_file='./saved_models/Decision_tree_regression_01.dot', feature_names=X.columns, filled=True, rounded=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
