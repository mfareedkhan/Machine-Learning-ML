{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NAIVE Bayes algorithm**\n",
    "> Naive Bayes Algorithm is a `classification` algorithm based on `Bayes Theorem`. It is called naive because it assumes that the features in a dataset are `independent of each other`. This assumption is not true in real life but it simplifies the computation and gives good results in most of the cases.\n",
    "\n",
    "It is probabilistic machine learning model that is used for classification task. Which describes the probability of an event based on prior knowledge of conditions related to the event. \n",
    "\n",
    "### **Bayes Theorem:**\n",
    "Bayes Theorem is a mathematical formula used for calculating `conditional probability`. It is defined as:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
    "\n",
    "where A and B are events and P(B) != 0\n",
    "- `P(A|B)` is the probability of event A occurring given that event B has already occurred.\n",
    "- `P(B|A)` is the probability of event B occurring given that event A has already occurred.\n",
    "- `P(A)` and P(B) are the probabilities of events A and B occurring independently.\n",
    "- `P(B)` is the probability of event B occurring.\n",
    "- `P(A|B)` is the posterior probability.\n",
    "- `P(B|A)` is the likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bayyes Theorm Example 1:**\n",
    "> Suppose we have a dataset of emails and we want to classify them as `spam` or `not spam`. We can use Bayes Theorem to calculate the probability of an email being spam given that it contains certain words.\n",
    "- We can calculate the probability of an email being spam given that it contains the word \"free\" and the word \"money\" as:\n",
    "- `P(spam|free, money) = P(free, money|spam)P(spam)/P(free, money)`\n",
    "- `P(spam|free, money) = P(free|spam)P(money|spam)P(spam)/P(free, money)`\n",
    "- `P(spam|free, money) = P(free|spam)P(money|spam)P(spam)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bayyes Theorm Example 2:**\n",
    "> Imagine you're a teacher with a class of teachers, and you know the following information:\n",
    "- 60% of the students owns a bicycle.\n",
    "- 30% of them bring their bicycle to school.\n",
    "- Of those students who do not own a bicycle, 10% bring their bicycle to school (maybe they borrow one from a friend).\n",
    "\n",
    "Now, if you see a student riding a bicycle to school, what is the probability that they own a bicycle?\n",
    "- Let's use Bayes' Theorem to solve this problem. We'll use the following notation:\n",
    "- A as the event \"students owns a bicycle\n",
    "- B as the event \"students bring their bicycle to school\n",
    "\n",
    "We know:\n",
    "- P(A) = 0.6 (probability of owning a bicycle)\n",
    "- P(B|A) = 0.3 (probability of bringing a bicycle to school given that they own a bicycle)\n",
    "- P(B|A') = 0.1 (probability of bringing a bicycle to school given that they don't own a bicycle)\n",
    "\n",
    "We want to find P(A|B) (probability of owning a bicycle given that they bring a bicycle to school).\n",
    "- We can use the formula:\n",
    "`P(A|B) = P(B|A)P(A)/P(B)`\n",
    "- The tricky part is finding P(B). We can use the law of total probability to find it:\n",
    "`P(B) = P(B|A)P(A) + P(B|A')P(A')`\n",
    "- P(B) = 0.3 * 0.6 + 0.1 * 0.4 = 0.18 + 0.04 = 0.22\n",
    "\n",
    "Now we can find P(A|B):\n",
    "- P(A|B) = P(B|A)P(A)/P(B) = 0.3 * 0.6 / 0.22 = `0.8182`\n",
    "\n",
    "So, if you see a student riding a bicycle to school, there's an 81.82% chance that they own a bicycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Naive Bayes Algorithm:**\n",
    "\n",
    "Naive Bayes Algorithm is based on Bayes Theorem. It is defined as:\n",
    "\n",
    "$$P(y|x_1,x_2,...,x_n) = \\frac{P(x_1,x_2,...,x_n|y)P(y)}{P(x_1,x_2,...,x_n)}$$\n",
    "\n",
    "where y is the class variable and x1, x2, ..., xn are the features.\n",
    "\n",
    "The algorithm assumes that the features are independent of each other. So, the above equation can be written as:\n",
    "\n",
    "$$P(y|x_1,x_2,...,x_n) = \\frac{P(x_1|y)P(x_2|y)...P(x_n|y)P(y)}{P(x_1,x_2,...,x_n)}$$\n",
    "\n",
    "The denominator is constant for a given input. So, the equation can be written as:\n",
    "\n",
    "$$P(y|x_1,x_2,...,x_n) \\propto P(x_1|y)P(x_2|y)...P(x_n|y)P(y)$$\n",
    "\n",
    "The class with the highest probability is the output of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Types of Naive Bayes Algorithm:**\n",
    "1. **Gaussian Naive Bayes:** It is used in classification when features are `continuous` and `normally distributed`.\n",
    "2. **Multinomial Naive Bayes:** It is used in text/document classification where the features are `frequencies of words` or tokens in a document.\n",
    "3. **Bernoulli Naive Bayes:** It is used in text/document classification when features are `binary values` (0 or 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Uses of Naive Bayes Algorithm:**\n",
    "- Email spam detection, sentiment analysis, etc.\n",
    "- Sentiment analysis\n",
    "- Document categorization\n",
    "- It is used in `recommendation systems`.\n",
    "- It is used in `medical diagnosis`.\n",
    "- It is used in `weather prediction`.\n",
    "- It is used in `face recognition`.\n",
    "- It is used in `credit scoring`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Advantages of Naive Bayes Algorithm:**\n",
    "- It is `simple` and `easy to implement`.\n",
    "- It is `fast` and `scalable`.\n",
    "- It can be used for `multi-class` classification.\n",
    "- It can make `real-time predictions`.\n",
    "- It is `robust` to `irrelevant features`.\n",
    "- It is `robust` to `missing data`.\n",
    "- It is `less sensitive` to `overfitting`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Limitations of Naive Bayes Algorithm:**\n",
    "- It assumes that the features are `independent` of each other which is not true in real life.\n",
    "- It is `sensitive` to `imbalanced` datasets.\n",
    "- Data scarcity can affect the performance of the algorithm.\n",
    "  - If a categorical variable has a category in the test dataset, which was not observed in training dataset, then the model will assign a `zero probability` and will be unable to make a prediction.\n",
    "- The algorithm might not perform if the features are highly `correlated`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
